# 밑시딥  📂6. 학습 관련 기술들

> 가중치 매개변수의 최적값을 탐색하는 <u>최적화 방법, 가중치 매개변수 초깃값, 하이퍼파라미터 설정 방법</u> 등과 같이 신경망 학습의 핵심 개념들을 배워보자.



## 1. 매개변수 갱신

> 신경망 학습의 목표 = 매개변수(weight, bias)의 최적값을 찾는 것! 👉 **`최적화(optimization)`**

😥 우리는 지금까지 최적의 매개변수 값을 찾기 위해 `기울기(미분)`을 이용했다. 이는 <u>확률적 경사 하강법(Stochastic Gradient Descent, SGD)</u> 방법으로, 보다 똑똑한 최적화 방법이 존재한다. 지금부터 SGD의 단점을 살펴보고 다른 최적화 기법을 알아보자.



### 1.2 확률적 경사 하강법(Stochastic Gradient Descent, SGD)

> 기울어진 방향으로 일정 거리만 간다. 

<img src="밑시딥 6. 학습 관련 기술들.assets/e 6.1.png" alt="e 6.1" style="zoom:50%;" />  

```python
class SGD:
    def __init__(self, lr=0.01):
        self.lr = lr
        # lr = learning rate(학습률) ==> 하이퍼파라미터
        
    def update(self, params, grads):
        for key in params.keys(): # keys = w1, b1, w2, b2, ...
            params[key] -= self.lr * grads[key] 
            
# SGD 호출
optimizer = SGD()
optimizer.update(params, grads)
```



### 1.3 SGD 단점

> SGD는 단순하고 구현이 쉽지만 때로는 비효율적일 때가 있다.

- 예를 들면, 아래와 같은 함수의 최솟값을 구하는 문제를 생각해보자. 

  <img src="밑시딥 6. 학습 관련 기술들.assets/e 6.2.png" alt="e 6.2" style="zoom:50%;" /> 

 <img src="밑시딥 6. 학습 관련 기술들.assets/fig 6-1.png" alt="fig 6-1" style="zoom:50%;" />

​													 	`[함수의 그래프와 등고선]`

<img src="밑시딥 6. 학습 관련 기술들.assets/fig 6-2.png" alt="fig 6-2" style="zoom: 33%;" /> 

​						`[함수의 기울기]`

> 기울기를 보면 y축 방향은 매우 크고 x축 방향은 매우 작다. 
>
> 최솟값이 되는 장소는 실제로 (0,0)이지만, 기울기 대부분은 (0,0) 방향을 가리키지 않는다.

- (-7, 2)에서 탐색을 시작해보자.

<img src="밑시딥 6. 학습 관련 기술들.assets/fig 6-3.png" alt="fig 6-3" style="zoom: 33%;" /> 

>  최솟값인 (0,0)까지 지그재그로 이동하여 비효율적이다.

##### 🔥 **`SGD 단점` **: <u>비등방성 함수</u>(방향에 따라 성질이 달라지는 함수)[특정한 좌표에서 기울기가 가르치는 지점이 변하는 경우가 존재하는 것]에서 탐색 경로가 비효율적임 



### 1.4 모멘텀(Momentum)

> '운동량'을 뜻하는 단어

1. 모멘텀 기법의 수식 표현

<img src="밑시딥 6. 학습 관련 기술들.assets/e 6.3.png" alt="e 6.3" style="zoom:50%;" /> 

- v : 속도(velocity) 👉 기울기 방향으로 힘을 받아 물체가 가속되는 것을 나타냄
- α : 물체가 아무런 힘을 받지 않을 때 서서히 하강시키는 역할
- αv : 이전 회차의 수정량

<img src="밑시딥 6. 학습 관련 기술들.assets/fig 6-4.png" alt="fig 6-4" style="zoom:50%;" /> 

- 기울기의 방향이 일정하면 v 가속, 기울기의 방향이 일정하지 않으면 v 영향 적음
- 이전 회차의 수정량에 영향을 받아 수정량이 급격하게 변화하는 것을 막고 부드럽게 수정함

```python
class Momentum:
    # α(momentum) 하이퍼파라미터가 더 늘어남
    def __init__(self, lr=0.01, momentum=0.9):
        # learning rate
        self.lr = lr
        # α (물체가 힘 받지 않을 때 하강시킬수 있는 변수)
        self.momentum = momentum
        self.v = None
        
    def update(self, params, grads):
        if self.v is None:
            self.v = {}
            for key, val in params.items(): # keys : w1, b1, w2, b2, ...
                self.v[key] = np.zeros_like(val) # val의 데이터 타입에 크기가 0인 배열
                
        for key in params.keys():
            self.v[key] = self.momentum*self.v[key] - self.lr*grads[key] 
            # self.momentum*self.v[key] : 이전 회차의 갱신량
            params[key] += self.v[key]
```

- 모멘텀을 사용하여 최적화 문제를 풀어보자.

<img src="밑시딥 6. 학습 관련 기술들.assets/fig 6-5.png" alt="fig 6-5" style="zoom: 33%;" /> 

> x축의 힘은 작지만 방향을 변하지 않아서 한 방향으로 일정하게 **`가속`** 
>
> y축은 힘은 크지만 위아래로 상충하여 속도가 안정적이지 않음



### 1.5 AdaGrad(Adaptive Gradient)

> 수정량이 자동으로 조정됨 => 알고리즘에 의해 학습률이 감소
>
> `학습률 감소(learning rate decay)` : 학습을 진행하면서 학습률을 점차 줄여가는 방법

- <u>AdaGrad</u> : 각각의 매개변수에 맞춤형 값을 만들어주는 방법

  ​					👉 개별 매개변수에 적응적으로(adaptive) 학습률을 조정



1. AdaGrad 수식

<img src="밑시딥 6. 학습 관련 기술들.assets/e 6.5.png" alt="e 6.5" style="zoom:50%;" /> 

- Θ : 행렬의 원소별 곱셈 => 제곱!

<img src="밑시딥 6. 학습 관련 기술들.assets/e 6.6.png" alt="e 6.6" style="zoom:50%;" /> 

- h는 무조건 증가! => 갱신량은 h가 분모에 있으므로 무조건 감소!

- 매개변수의 원소 중에서 많이 움직인(크게 갱신된) 원소는 학습률이 낮아짐



2. AdaGrad 구현

   ```python
   class AdaGrad:
       def __init__(self, lr=0.01):
           self.lr = lr
           self.h = None
           
       def update(self, params, grads):
           if self.h is None:
               self.h = {}
               for key, val in params.items():
                   self.h[key] = np.zeros_like(val)
               
           for key in params.keys():
               self.h[key] += grads[key] * grads[key]
               params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)
               # 1e-7 : 0으로 나누는 것을 막기 위해
   ```

- AdaGrad를 사용하여 최적화 문제를 풀어보자.

 

> y축 방향은 기울기가 커서 처음에는 크게 움직이지만, 그에 비례해 갱신 정도도 큰 폭으로 작아지도록 조정됨

🤷‍♀️ AdaGrad는 무한히 학습한다면 갱신 값은 0이 됨. 그래서 먼 과거의 기울기 정보는 잊고 새로운 기울기 정보를 크게 반영하는 지수이동평균(Exponential moving average, EMA)을 이용한 기법인 `RMSProp` 사용하기도함.

<img src="밑시딥 6. 학습 관련 기술들.assets/fig 6-6.png" alt="fig 6-6" style="zoom: 33%;" /> 

3. RMSProp 구현

   > 아다그라드에서 갱신량 감소를 통해 통해 학습이 정체되는 단점을 극복한 방법

     <img src="밑시딥 6. 학습 관련 기술들.assets/e 6.9.png" alt="e 6.9" style="zoom:67%;" />
   
   - ρ (decay_rate) : 이전 시점의 h를 적당한 비율로 감소시킴 ==> 옛 정보일수록 많이 감소됨
   
   ```python
   class RMSprop:
       def __init__(self, lr=0.01, decay_rate = 0.99):
           self.lr = lr
           self.decay_rate = decay_rate
           self.h = None
           
       def update(self, params, grads):
           if self.h is None:
               self.h = {}
               for key, val in params.items():
                   self.h[key] = np.zeros_like(val)
               
           for key in params.keys():
            self.h[key] *= self.decay_rate
               self.h[key] += (1 - self.decay_rate) * grads[key] * grads[key]
               params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)
   ```
   
   

### 1.6 📌Adam

> 모멘텀(부드러운 갱신) + AdaGrad(각 매개변수의 적응적인 갱신)

1. 특징

   - 하이퍼파라미터의 '편향 보정'이 진행된다.

2. Adam 구현

    <img src="밑시딥 6. 학습 관련 기술들.assets/e 6.10.png" alt="e 6.10" style="zoom:50%;" />
   
   ```python
   class Adam:
       def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):
           self.lr = lr
           self.beta1 = beta1
           self.beta2 = beta2
           self.iter = 0
           self.m = None
           self.v = None
           
       def update(self, params, grads):
           if self.m is None:
               self.m, self.v = {}, {}
               for key, val in params.items():
                   self.m[key] = np.zeros_like(val)
                   self.v[key] = np.zeros_like(val)
           
           self.iter += 1
           # 갱신을 반복할수록 lr 감소
           lr_t  = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)         
           
           for key in params.keys():
               #self.m[key] = self.beta1*self.m[key] + (1-self.beta1)*grads[key]
               #self.v[key] = self.beta2*self.v[key] + (1-self.beta2)*(grads[key]**2)
               self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])
               self.v[key] += (1 - self.beta2) * (grads[key]**2 - self.v[key])
               
               params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)
   ```
   

<img src="밑시딥 6. 학습 관련 기술들.assets/fig 6-7.png" alt="fig 6-7" style="zoom:33%;" /> 

> 모멘텀과 비슷한 패턴이지만 학습의 갱신 강도를 적응적으로 조정해서 좌우 흔들림 적음



### 1.7 어떤 갱신 방법을 이용할 것인가?

> SGD vs 모멘텀 vs AdaGrad vs Adam

- 각자의 상황을 고려해 여러 가지로 시도



### 1.8 MNIST 데이터셋으로 본 갱신 방법 비교

```python
# 0. MNIST 데이터 읽기==========
(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)

train_size = x_train.shape[0]
batch_size = 128
max_iterations = 2000


# 1. 실험용 설정==========
optimizers = {}
optimizers['SGD'] = SGD()
optimizers['Momentum'] = Momentum()
optimizers['AdaGrad'] = AdaGrad()
optimizers['Adam'] = Adam()

networks = {}
train_loss = {}
for key in optimizers.keys():
    networks[key] = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100],output_size=10)
    # hidden_size_list는 은닉층이 4개 있음을 뜻함(가중치 100개)
    train_loss[key] = []    


# 2. 훈련 시작==========
for i in range(max_iterations):
    # batch사이즈에 맞게 할당
    batch_mask = np.random.choice(train_size, batch_size)
    x_batch = x_train[batch_mask]
    t_batch = t_train[batch_mask]
    
    for key in optimizers.keys():
        # 기울기 구하기
        grads = networks[key].gradient(x_batch, t_batch)
        # 각 최적화(갱신)에 맞게 최적화하기
        optimizers[key].update(networks[key].params, grads)
    	# loss 구하기
        loss = networks[key].loss(x_batch, t_batch)
        train_loss[key].append(loss)
    
    if i % 100 == 0:
        print( "===========" + "iteration:" + str(i) + "===========")
        for key in optimizers.keys():
            loss = networks[key].loss(x_batch, t_batch)
            print(key + ":" + str(loss))


# 3. 그래프 그리기==========
markers = {"SGD": "o", "Momentum": "x", "AdaGrad": "s", "Adam": "D"}
x = np.arange(max_iterations)
for key in optimizers.keys():
    plt.plot(x, smooth_curve(train_loss[key]), marker=markers[key], markevery=100, label=key)
    # smooth_curve는 따로 지정한 함수 : 부드러운 곡선 그래프 그리는 함수
plt.xlabel("iterations")
plt.ylabel("loss")
plt.ylim(0, 1)
plt.legend()
plt.show()
```

<img src="밑시딥 6. 학습 관련 기술들.assets/Figure_1.png" alt="Figure_1" style="zoom:72%;" /> 

> 주의할 점. 하이퍼파라미터에 다라 결과는 달라진다. 일반적으로 SGD보다 다른 세 기법이 빠르게 학습하며 정확도가 높게 나타난다.



---



## 2. ✨가중치의 초깃값

> 가중치의 초깃값을 무엇으로 설정하느냐는 신경망 학습에서 매우 중요하다. 



### 2.1 초깃값을 0으로 하면?

🔥 **`가중치 감소(weight decay)`** : 오버피팅을 억제해 범용 성능을 높이는 테크닉

​															👉 가중치 값이 작아지도록 학습하는 방법 

======> 가중치 값을 작게 하면 오버피팅이 일어나지 않는다!

======> 가중치는 입력의 영향력을 제어하기 때문에!!

​				 가중치가 작다면 입력의 영향력을 작게하기 때문에 특정 데이터에 오버피팅되지 않음!



❓ <u>그렇다면 가중치 초깃값을 모두 0으로 하면 되지 않을까</u> ❓

🆖 가중치를 <u>균일한 값</u>으로 설정하면 오차역전파법에서 모든 가중치의 값이 똑같이 갱신된다. 



### 2.2 은닉층의 활성화값 분포

> 은닉층의 활성화값(활성화 함수의 출력 데이터)의 분포를 통해 신경망 학습이 효율적으로 이루어지고 있는지 확인할 수 있다.

- 은닉층의 활성화값 분포를 히스토그램으로 그려보자.

  ```python
  # 시그모이드 활성화 함수
  def sigmoid(x):
      return 1 / (1 + np.exp(-x))
  
  # ReLU 활성화 함수
  def ReLU(x):
      return np.maximum(0, x)
  
  # tanh 활성화 함수
  def tanh(x):
      return np.tanh(x)
  
  # 입력 데이터 무작위로 생성
  x = np.random.randn(1000, 100)  # 1000개의 데이터
  node_num = 100  # 각 은닉층의 노드(뉴런) 수
  hidden_layer_size = 5  # 은닉층 5개
  activations = {}  # 활성화 결과 저장
  
  # 각 은닉층 탐색
  for i in range(hidden_layer_size):
      # 앞에 계산한 x*w의 값을 받아서 해당 은닉층의 가중치와 곱해서 계산하기 위해 앞의 계산값 불러옴
      if i != 0:
          x = activations[i-1]
  
      # 초깃값 실험
      # 표준편차가 1인 정규분포
      w = np.random.randn(node_num, node_num) * 1 # (1)
      # 표준편차가 0.01인 정규분포
      w = np.random.randn(node_num, node_num) * 0.01 # (2)
      # Xavier 초깃값
      w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num) # (3)  
      # He 초깃값(ReLU 특화 초깃값)
      w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num)  # (4)
  
      a = np.dot(x, w)
      z = sigmoid(a)
      # z = ReLU(a)
      # z = tanh(a)
  	
      # 활성화 값
      activations[i] = z
  
  # 히스토그램 그리기
  for i, a in activations.items():
      plt.subplot(1, len(activations), i+1)
      plt.title(str(i+1) + "-layer")
      if i != 0: plt.yticks([], [])
      plt.hist(a.flatten(), 30, range=(0,1))
  plt.show()
  ```



(1) 표준편차가 1인 정규분포

​	<img src="밑시딥 6. 학습 관련 기술들.assets/fig 6-10.png" alt="fig 6-10" style="zoom:50%;" /> 

> 활성화값들이 0, 1에 치우쳐 분포 ==> 역전파의 기울기 값이 작아지다가 사라짐 

> **`기울기 소설(gradient vanishing)`** 발생!

  <img src="밑시딥 6. 학습 관련 기술들.assets/Figure_2.png" alt="Figure_2" style="zoom:50%;" />

[Sigmoid 활성화함수는 input 값이 0에서 멀어질수록 미분값은 0으로 작아지므로 backward propagation에서 기울기 값도 매우 작아짐]



(2) 표준편차가 0.01인 정규분포

<img src="밑시딥 6. 학습 관련 기술들.assets/fig 6-11.png" alt="fig 6-11" style="zoom:50%;" /> 

> 활성화값들이 한곳으로 치우침 ==> 다수의 뉴런이 같은 값을 출력 ==> 다수의 뉴런 의미 X
>
> **`표현력 제한`** 발생!

🙄 위의 경우들을 보았을 때, 활성화값은 <u>적당히 골고루 분포</u>되어야 함을 알 수 있다.



(3) ✨ **`Xavier 초깃값`**

> 각 층의 활성화값들을 광범위하게 분포시키기 위한 초깃값 설정

<img src="밑시딥 6. 학습 관련 기술들.assets/e 6.11.png" alt="e 6.11" style="zoom:67%;" /> n : 앞 계층의 노드 수

<img src="밑시딥 6. 학습 관련 기술들.assets/fig 6-13.png" alt="fig 6-13" style="zoom:50%;" /> 

- sigmoid 함수 대신 tanh함수를 사용하면 일그러진 모양을 개선할 수 있음 => tanh 함수는 (0,0) 대칭이기 때문


<img src="밑시딥 6. 학습 관련 기술들.assets/Figure_3.png" alt="Figure_3" style="zoom:50%;" /> 



### 2.3 ReLU를 사용할 때의 가중치 초깃값

> Xavier 초깃값은 활성화 함수가 선형인 것을 전제 ==> ReLU에 특화된 초깃값 이용 권장!!
>
> 👉 **`He 초깃값`**

```python
# He 초깃값(ReLU 특화 초깃값)
w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num)  # (4)
```

- 직감적으로 ReLU는 음의 영역이 0이라서 더 넓게 분포시키기 위해 Xavier 초깃값보다 2배의 계수 필요

<img src="밑시딥 6. 학습 관련 기술들.assets/fig 6-14.png" alt="fig 6-14" style="zoom:50%;" /> 



### 2.4 MNIST 데이터셋으로 본 가중치 초깃값 비교

```python
# 1. 실험용 설정(가중치 초깃값)==========
weight_init_types = {'std=0.01': 0.01, 'Xavier': 'sigmoid', 'He': 'relu'}
optimizer = SGD(lr=0.01) # 최적화 SGD

networks = {}
train_loss = {}
for key, weight_type in weight_init_types.items():
    networks[key] = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100], output_size=10, weight_init_std=weight_type) # 초깃값을 딕셔너리 value값으로 받음
    train_loss[key] = []


# 2. 훈련 시작==========
for i in range(max_iterations):
    batch_mask = np.random.choice(train_size, batch_size)
    x_batch = x_train[batch_mask]
    t_batch = t_train[batch_mask]
    
    for key in weight_init_types.keys():
        grads = networks[key].gradient(x_batch, t_batch)
        optimizer.update(networks[key].params, grads)
    
        loss = networks[key].loss(x_batch, t_batch)
        train_loss[key].append(loss)
```

```python
def __init_weight(self, weight_init_std):
    """가중치 초기화
    Parameters
    ----------
    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）
        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정
        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정
    """
    all_size_list = [self.input_size] + self.hidden_size_list + [self.output_size]
    for idx in range(1, len(all_size_list)):
        scale = weight_init_std
        if str(weight_init_std).lower() in ('relu', 'he'):
            scale = np.sqrt(2.0 / all_size_list[idx - 1])  # ReLU를 사용할 때의 권장 초깃값
        elif str(weight_init_std).lower() in ('sigmoid', 'xavier'):
            scale = np.sqrt(1.0 / all_size_list[idx - 1])  # sigmoid를 사용할 때의 권장 초깃값
        self.params['W' + str(idx)] = scale * np.random.randn(all_size_list[idx-1], all_size_list[idx])
        self.params['b' + str(idx)] = np.zeros(all_size_list[idx])
```

<img src="밑시딥 6. 학습 관련 기술들.assets/fig 6-15.png" alt="fig 6-15" style="zoom: 33%;" /> 

> 기본 인자로 활성화 함수를 relu로 설정함. 때문에 xavier과 he의 학습이 월등히 좋음.



---



## 3. 배치 정규화(Batch Normalization)

> 각 층이 활성화를 적당히 퍼뜨리도록 강제하는 것



### 3.1 배치 정규화 알고리즘

1. 특징
   - 학습 속도 개선
   - 초깃값에 크게 의존 X
   - 오버피팅 억제



2. 배치 정규화(Batch Norm) 계층

   >  데이터 분포를 정규화

   <img src="밑시딥 6. 학습 관련 기술들.assets/fig 6-16.png" alt="fig 6-16" style="zoom:50%;" /> 

   - 데이터 분포가 평균 0, 분산 1이 되도록 정규화하자.

   - 정규화 수식

     <img src="밑시딥 6. 학습 관련 기술들.assets/e 6.7.png" alt="e 6.7" style="zoom:50%;" /> 

     > μ : 평균 /  σ : 분산

   - 고유한 확대(scale) 와 이동(shift) 변환 수행

     <img src="밑시딥 6. 학습 관련 기술들.assets/e 6.8.png" alt="e 6.8" style="zoom:50%;" /> 

     > γ=1, β=0으로 시작해서 학습하면서 적합한 값으로 조정

   <img src="밑시딥 6. 학습 관련 기술들.assets/fig 6-17.png" alt="fig 6-17" style="zoom:50%;" /> 



### 3.2 배치 정규화의 효과

> MNIST 데이터셋을 사용하여 실험해본 결과, 학습 속도를 높인다는 결론이 도출됨

<img src="밑시딥 6. 학습 관련 기술들.assets/fig 6-19.png" alt="fig 6-19" style="zoom:50%;" /> 

- 배치 정규화 구현

```python
class BatchNormalization:
    def __init__(self, gamma, beta, momentum=0.9, running_mean=None, running_var=None):
        self.gamma = gamma
        self.beta = beta
        self.momentum = momentum
        self.input_shape = None # 합성곱 계층(convolutional layer)은 4차원, 완전연결 계층(fully connected layer/ affine 계층)은 2차원  

        # 시험할 때 사용할 평균과 분산
        self.running_mean = running_mean
        self.running_var = running_var  
        
        # backward 시에 사용할 중간 데이터
        self.batch_size = None
        self.xc = None
        self.std = None
        self.dgamma = None # γ 미분값
        self.dbeta = None # β 미분값

    def forward(self, x, train_flg=True):
        self.input_shape = x.shape
        if x.ndim != 2:
            N, C, H, W = x.shape
            x = x.reshape(N, -1)

        out = self.__forward(x, train_flg)
        
        return out.reshape(*self.input_shape)
            
    def __forward(self, x, train_flg):
        if self.running_mean is None:
            N, D = x.shape
            self.running_mean = np.zeros(D)
            self.running_var = np.zeros(D)
                        
        if train_flg: # 배치 정규화 한다면 => 입력 값들을 정규화
            mu = x.mean(axis=0)
            xc = x - mu
            var = np.mean(xc**2, axis=0)
            std = np.sqrt(var + 10e-7)
            xn = xc / std # 정규화 수식 
            
            self.batch_size = x.shape[0]
            self.xc = xc
            self.xn = xn
            self.std = std
            self.running_mean = self.momentum * self.running_mean + (1-self.momentum) * mu
            self.running_var = self.momentum * self.running_var + (1-self.momentum) * var            
        else:
            xc = x - self.running_mean
            xn = xc / ((np.sqrt(self.running_var + 10e-7)))
            
        out = self.gamma * xn + self.beta 
        return out

    def backward(self, dout):
        if dout.ndim != 2:
            N, C, H, W = dout.shape
            dout = dout.reshape(N, -1)

        dx = self.__backward(dout)

        dx = dx.reshape(*self.input_shape)
        return dx

    def __backward(self, dout): # γ, β의 미분값 구해서 적절한 값으로 갱신
        dbeta = dout.sum(axis=0)
        dgamma = np.sum(self.xn * dout, axis=0)
        dxn = self.gamma * dout
        dxc = dxn / self.std
        dstd = -np.sum((dxn * self.xc) / (self.std * self.std), axis=0)
        dvar = 0.5 * dstd / self.std
        dxc += (2.0 / self.batch_size) * self.xc * dvar
        dmu = np.sum(dxc, axis=0)
        dx = dxc - dmu / self.batch_size
        
        self.dgamma = dgamma
        self.dbeta = dbeta
        
        return dx
```



---



## 4. 바른 학습을 위해

> 신경망이 훈련 데이터에 지나치게 적응되어 범용 성능을 낮추는 것을 **`오버피팅`**이라고 한다.



### 4.1 오버피팅

1. 오버피팅이 일어나는 경우
   - 매개변수가 많고 표현력이 높은 모델
   - 훈련데이터가 적음

- 위의 요건을 충족시켜 오버피팅을 일으켜보자.

  ```python
  # MNIST 데이터셋의 훈련데이터를 300개만 사용하고, 7층의 네트워크를 사용해보자.
  (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)
  
  # 오버피팅을 재현하기 위해 학습 데이터 수를 줄임 300개만 들고옴
  x_train = x_train[:300]
  t_train = t_train[:300]
  
  # weight decay（가중치 감쇠） 설정 =======================
  weight_decay_lambda = 0 # weight decay(가중치 감소)를 사용하지 않을 경우
  weight_decay_lambda = 0.1 # weight decay(가중치 감소)를 사용한 경우, lambda = 0.1로 설정
  # ====================================================
  
  network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10,weight_decay_lambda=weight_decay_lambda)
  optimizer = SGD(lr=0.01) # 학습률이 0.01인 SGD로 매개변수 갱신
  
  max_epochs = 201
  train_size = x_train.shape[0] # 300
  batch_size = 100
  
  train_loss_list = []
  train_acc_list = []
  test_acc_list = []
  
  iter_per_epoch = max(train_size / batch_size, 1) # 3
  epoch_cnt = 0
  
  for i in range(1000000000):
      batch_mask = np.random.choice(train_size, batch_size)
      x_batch = x_train[batch_mask]
      t_batch = t_train[batch_mask]
  
      grads = network.gradient(x_batch, t_batch)
      optimizer.update(network.params, grads)
  
      if i % iter_per_epoch == 0:
          train_acc = network.accuracy(x_train, t_train)
          test_acc = network.accuracy(x_test, t_test)
          train_acc_list.append(train_acc)
          test_acc_list.append(test_acc)
  
          print("epoch:" + str(epoch_cnt) + ", train acc:" + str(train_acc) + ", test acc:" + str(test_acc))
  
          epoch_cnt += 1
          if epoch_cnt >= max_epochs:
              break
  ```

    

  <img src="밑시딥 6. 학습 관련 기술들.assets/Figure_4.png" alt="Figure_4" style="zoom:50%;" /> <img src="밑시딥 6. 학습 관련 기술들.assets/Figure_5.png" alt="Figure_5" style="zoom:50%;" />

> 왼쪽 그래프처럼 정확도가 크게 벌어지는 것은 훈련데이터에만 적응해버린 결과이다.

> 오른쪽 그래프는 가중치 감소를 사용한 경우이다.



### 4.2 가중치 감소(weight decay)

> 가중치가 작을수록 오버피팅은 억제된다.  가중치의 `제곱 노름(L2 norm)`을 <u>손실함수에 더하면</u> 가중치가 커지는 것을 억제할 수 있다.  => 가중치가 클수록 패널티(손실에 대한)를 준다.

* 제곱 노름(L2 norm) : 각 원소의 제곱들을 더한 것

```python
def loss(self, x, t, train_flg=False):
"""손실 함수를 구한다.
	Parameters
	----------
	x : 입력 데이터
	t : 정답 레이블 
"""

y = self.predict(x, train_flg)

weight_decay = 0
for idx in range(1, self.hidden_layer_num + 2):
    W = self.params['W' + str(idx)]
    weight_decay += 0.5 * self.weight_decay_lambda * np.sum(W**2) # 가중치 감소 사용하여 오버피팅 막음

return self.last_layer.forward(y, t) + weight_decay # loss에 가중치 감소 더해줌 
```

> λ(weight_decay_lambda) : 정규화의 세기를 조절하는 하이퍼파라미터

<img src="밑시딥 6. 학습 관련 기술들.assets/e 6.12.png" alt="e 6.12" style="zoom:67%;" /> 

- 역전파법을 사용하면 아래와 같이 계산할 것같다.

<img src="밑시딥 6. 학습 관련 기술들.assets/e 6.13.png" alt="e 6.13" style="zoom:67%;" /> 

> 가중치 감소란 가중치의 `크기`가 감소된다는 뜻으로 이해!!



### 4.3 드롭아웃(Dropout)

> 뉴런을 임의로 삭제하면서 학습하는 방법

```python
class Dropout:
    def __init__(self, dropout_ratio=0.5):
        self.dropout_ratio = dropout_ratio
        self.mask = None

    def forward(self, x, train_flg=True):
        if train_flg:
            # x와 형상이 같은 배열을 무작위로 생성 
            # dropout_ratio보다 큰 값들은 True로 표시, 작은 값들은 False로 표시
            self.mask = np.random.rand(*x.shape) > self.dropout_ratio
            return x * self.mask
        else:
            return x * (1.0 - self.dropout_ratio)

    def backward(self, dout):
        # 순전파때 통과한 뉴런은 역전파때도 통과한다.
        return dout * self.mask
```

<img src="밑시딥 6. 학습 관련 기술들.assets/fig 6-23.png" alt="fig 6-23" style="zoom:50%;" /> 

> 표현력을 높이면서 오버피팅을 억제하는 방법

- 앙상블 학습(ensemble learning) : 개별적으로 학습시킨 여러 모델의 출력을 평균내어 추론하는 방식

  > 드롭아웃은 앙상블 학습과 같은 효과를 얻는다.



---



## 5. 적절한 하이퍼파라미터 값 찾기

> 하이퍼파라미터의 값을 적절히 설정하지 않으면 모델의 성능이 크게 떨어질 것이다.
>
> 하이퍼파라미터의 값을 최대한 효율적으로 탐색하는 방법을 알아보자.



### 5.1 검증 데이터(validation data)

> 하이퍼파라미터의 성능을 평가할 때는 시험 데이터를 사용해서 안 된다.

​	🤷‍♀️ why? 하이퍼파라미터 값이 시험 데이터에  오버피팅되기 때문

​			👉 하이퍼파라미터 조정용 데이터 = validation data

| data        | 역할                     |
| ----------- | ------------------------ |
| 훈련 데이터 | 매개변수 학습            |
| 검증 데이터 | 하이퍼파라미터 성능 평가 |
| 시험 데이터 | 신경망의 범용 성능 평가  |

```python
# 20%를 검증 데이터로 분할
validation_rate = 0.20
validation_num = int(x_train.shape[0] * validation_rate)

# train, validation으로 나누기 전에 데이터 shuffle
x_train, t_train = shuffle_dataset(x_train, t_train)
x_val = x_train[:validation_num]
t_val = t_train[:validation_num]
x_train = x_train[validation_num:]
t_train = t_train[validation_num:]
```

```python
def shuffle_dataset(x, t):
    permutation = np.random.permutation(x.shape[0]) 
    # 0~x.shape[0]-1의 숫자들이 섞임
    x = x[permutation,:] if x.ndim == 2 else x[permutation,:,:,:]
    # permutation 조합
    t = t[permutation]

    return x, t
```



### 5.2 하이퍼파라미터 최적화

> 핵심 : 하이퍼파라미터의 `최적값` 이 존재하는 범위를 조금씩 줄여간다는 것

1. 대략적인 범위를 설정
2. 그 범위에서 무작위로 하이퍼파라미터 값을 골라냄(샘플링)
3. 정확도를 평가

- 딥러닝 학습에는 오랜 시간이 걸리므로 에폭 작게 하여 시간을 단축하는 것이 효과적



### 5.3 하이퍼파라미터 최적화 구현하기

> MNIS 데이터셋을 사용해 학습률과 가중치 감소의 계수를 최적화해보자.

```python
# 하이퍼파라미터 무작위 탐색======================================
optimization_trial = 100
results_val = {}
results_train = {}
for _ in range(optimization_trial):
    # 탐색한 하이퍼파라미터의 범위 지정===============
    weight_decay = 10 ** np.random.uniform(-8, -4) # 10^(-8) ~10^(-4) 중 샘플링
    lr = 10 ** np.random.uniform(-6, -2) # 10^(-6) ~ 10^(-2)
    # ================================================

    val_acc_list, train_acc_list = __train(lr, weight_decay)
    print("val acc:" + str(val_acc_list[-1]) + " | lr:" + str(lr) + ", weight decay:" + str(weight_decay))
    key = "lr:" + str(lr) + ", weight decay:" + str(weight_decay)
    results_val[key] = val_acc_list
    results_train[key] = train_acc_list
```
