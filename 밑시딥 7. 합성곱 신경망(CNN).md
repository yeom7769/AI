# 밑시딥 📂7. 합성곱 신경망(CNN)

> 합성곱 신경망(convolutional neural network)
>
> CNN은 이미지 인식과 음성 인식 등에 사용되는 신경망으로써 이미지 인식 분야의 기초가 된다.



## 1. 전체 구조

> CNN에서는 기존의 완전연결(fully-connected)인 Affine 계층뿐만 아닌 **`합성곱 계층(Conv)`**과 **`풀링 계층(Pooling)`**이 추가된다.

![fig 7-2](밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-2.png)

- CNN의 계층은 'Conv-ReLU-(Pooling)'흐름으로 연결



## 2. 합성곱 계층

> CNN에서는 패딩(padding), 스트라이드(stride) 등 새로운 개념이 등장하며 계층 사이에는 입체적인 데이터가 흐른다.



### 2.1 완전연결 계층의 문제점

> 완전연결 계층 : 인접하는 계층의 뉴런이 모두 연결

🔥  완전연결 계층의 단점 : <u>**`데이터의 형상이 무시`**</u>

- 이미지는 일반적으로 세로, 가로, 채널(색상)으로 구성된 3차원 데이터이다.

- 완전연결 계층의 입력은 <u>3차원 데이터를 평평한 1차원 데이터</u>로 평탄화해줘야 함

  👉 3차원 속에서 의미를 갖는 본질적인 패턴이 숨어 있을 것인데 완전연결 계층은 형상에 담긴 정보를 살릴 수 없다.



✨ 특징 맵(feature map) : 합성곱 계층의 입출력 데이터



### 2.2 합성곱 연산

> 합성곱 연산 : 필터 연산

<img src="밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-3.png" alt="fig 7-3" style="zoom: 50%;" />  

> 입력과 필터에서 대응하는 원소끼리 곱한 후 그 총합을 구함 ===> `단일 곱셈-누산(FMA)`



<img src="밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-4.png" alt="fig 7-4" style="zoom:50%;" /> 

- 완전연결 신경망에는 가중치와 편향이 존재하지만 CNN에서는 필터가 존재한다. 즉, 필터가 가중치의 역할을 하는 것이다.

- 편향 또한 고려한다면 아래와 같음. <u>편향은 항상 하나(1X1)만 존재</u>

<img src="밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-5.png" alt="fig 7-5" style="zoom:50%;" /> 



### 2.3 패딩(padding)

> 입력 데이터 주변을 특정 값으로 채우는 것

- 왜 사용?? ==> 출력 크기를 조정할 목적
  - 합성곱 연산을 거칠 때마다 크기가 작아지면 어느 시점에서는 출력 크기가 1이 되어버리기 때문

<img src="밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-6.png" alt="fig 7-6" style="zoom:50%;" /> 



### 2.4 스트라이드(stride)

> 필터를 적용하는 위치의 간격

- 스트라이드를 키우면 출력 크기는 작아진다. 반대로 패딩을 키우면 출력 크기는 커진다. 이를 수식화하면 아래와 같다.

  <img src="밑시딥 7. 합성곱 신경망(CNN).assets/e 7.1.png" alt="e 7.1" style="zoom:50%;" /> > 

  > 입력 크기 (H, W), 필터 크기(FH, FW), 출력 크기(OH, OW), 패딩 P, 스트라이드 S
  >
  > 출력 크기는 정수로 떨어져야함을 주의!



### 2.5 3차원 데이터의 합성곱 연산

> 채널까지 고려한 3차원 데이터를 다루는 합성곱 연산을 살펴보자.

<img src="밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-9.png" alt="fig 7-9" style="zoom:50%;" /> 

> 입력 데이터의 채널 수와 필터의 채널 수가 같아야 함!



### 2.6 블록으로 생각하기

> 3차원 데이터를 다차원 배열로 나타낼 때는 (채널, 높이, 너비) 순서를 쓰자.
>
> 필터 또한 (채널, 필터높이, 필터너비)로 나타낸다고 하자.

<img src="밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-10.png" alt="fig 7-10" style="zoom:50%;" /> 

> 출력이 2차원으로 나옴(출력 특징 맵이 한 장) ==> 3차원으로 출력할려면? 👇



<img src="밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-11.png" alt="fig 7-11" style="zoom:50%;" /> 

> 필터를 다수 사용 ==> 필터 FN개 사용하면 출력 또한 FN 장의 출력 특징 맵이 생김
>
> 가중치 데이터 = (출력 채널 수, 입력 채널 수, 높이, 너비)



<img src="밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-12.png" alt="fig 7-12" style="zoom:50%;" /> 

> 편향은 채널 하나에 값 하나씩으로 구성





### 2.7 배치 처리

> 입력 데이터를 한 덩어리로 묶어 배치 처리

<img src="밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-13.png" alt="fig 7-13" style="zoom: 50%;" /> 

> 데이터를 (데이터 수, 채널 수, 높이, 너비) 순으로 저장

- 주의할 점. 신경망 4차원 데이터가 하나 흐를 때마다 데이터 N개에 대한 합성곱 연산이 이뤄짐 ==> N회 분의 처리를 한번에 수행



---



## 3. 풀링 계층

> 세로, 가로 방향의 공간을 줄이는 연산

<img src="밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-14.png" alt="fig 7-14" style="zoom:50%;" />

- 위의 그림은 **`최대 풀링(max pooling)`**을 스트라이드 2로 처리한다. 보통 풀링의 윈도우 크기와 스트라이드는 같은 값으로 설정한다.
- 풀링으로는 평균 풀링 등이 있지만 이미지 인식 분야에서는 주로 최대 풀링을 사용함



### 3. 1 풀링 계층의 특징

1. 학습해야 할 매개변수 없음
2. 채널 수가 변하지 않음
   - 채널마다 독립적으로 계산하기 때문
3. 입력의 변화에 영향을 적게 받음(강건하다)
   - 데이터에 따라 다를 수도 있음



---



## 4. 합성곱/풀링 계층 구현하기

> 합성곱과 풀링 계층을 파이썬으로 구현해보자.



### 4.1 4차원 배열

> CNN에서 계층 사이로 흐르는 데이터는 4차원이다.

```python
x = np.random.rand(10, 1, 28, 28)
x.shape # (10, 1, 28, 28)
# 높이 28, 너비 28, 채널 1개인 데이터가 10개

x[i] # 각 데이터 접근
x[i][j] # 채널 접근 (x[i, j])
```



### 4.2 im2col로 데이터 전개하기

> 넘파이 에서는 원소에 접근할 때 for 문을 사용하지 않는다. 떄문에 `im2col` 이라는 함수를 사용하여 간단하게 구현할 수 있다.

🙄 im2col : image to column

​					 👉 입력 데이터를 필터링하기 좋게 전개하는 함수로 4차원 데이터를 2차원으로 변환함

<img src="밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-18.png" alt="fig 7-18" style="zoom:50%;" /> 

> 입력 데이터에서 필터를 적용하는 영역을 한 줄로 늘어놓는다.

- 그림에서는  필터의 적용 영역이 겹치지 않지만 실제 상황에서는 영역이 겹치는 경우가 대부분

  👉 im2col로 전개한 후의 원소 수가 원래 블록의 원소 수보다 많아짐 ==> 메모리 많이 소비



<img src="밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-19.png" alt="fig 7-19" style="zoom:50%;" />

> 합성곱 계층의 필터를 1열로 전개하고 계산. 2차원인 출력 데이터를 4차원으로 변형(reshape)해야함



### 4.3 합성곱 계층 구현하기

- im2col 함수

  ```python
  def im2col(input_data, filter_h, filter_w, stride=1, pad=0):
      """다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).
      
      Parameters
      ----------
      input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)
      filter_h : 필터의 높이
      filter_w : 필터의 너비
      stride : 스트라이드
      pad : 패딩
      
      Returns
      -------
      col : 2차원 배열
      """
      N, C, H, W = input_data.shape
      out_h = (H + 2*pad - filter_h)//stride + 1
      out_w = (W + 2*pad - filter_w)//stride + 1
  
      img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')
      col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))
  
      for y in range(filter_h):
          y_max = y + stride*out_h
          for x in range(filter_w):
              x_max = x + stride*out_w
              col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]
  
      col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)
      # transpose() : 다차원 배열의 축 순서를 바꿔주는 함수(인덱스로 축의 순서를 변경) 
      # (N, C, filter_h, filter_w, out_h, out_w) => (N, out_h, out_w, C, filter_h, filter_w)
      # reshape에 -1을 지정하면 다차원 배열의 원 수가 변환 후에도 똑같이 유지되도록 절적히 묶어줌
      return col
  ```

- Convolution class

  ```python
  class Convolution:
      def __init__(self, W, b, stride=1, pad=0):
          self.W = W
          self.b = b
          self.stride = stride
          self.pad = pad
          
          # 중간 데이터（backward 시 사용）
          self.x = None   
          self.col = None
          self.col_W = None
          
          # 가중치와 편향 매개변수의 기울기
          self.dW = None
          self.db = None
  
      def forward(self, x):
          FN, C, FH, FW = self.W.shape
          N, C, H, W = x.shape
          out_h = 1 + int((H + 2*self.pad - FH) / self.stride)
          out_w = 1 + int((W + 2*self.pad - FW) / self.stride)
  
          col = im2col(x, FH, FW, self.stride, self.pad)
          col_W = self.W.reshape(FN, -1).T
  
          out = np.dot(col, col_W) + self.b
          out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)
  
          self.x = x
          self.col = col
          self.col_W = col_W
  
          return out
  
      def backward(self, dout):
          FN, C, FH, FW = self.W.shape
          dout = dout.transpose(0,2,3,1).reshape(-1, FN)
  
          self.db = np.sum(dout, axis=0)
          self.dW = np.dot(self.col.T, dout)
          self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)
  
          dcol = np.dot(dout, self.col_W.T)
          dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)
  
          return dx
  ```

- backward 시 im2col은 col2im함수로 사용

  ```python
  def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):
      """(im2col과 반대) 2차원 배열을 입력받아 다수의 이미지 묶음으로 변환한다.
      
      Parameters
      ----------
      col : 2차원 배열(입력 데이터)
      input_shape : 원래 이미지 데이터의 형상（예：(10, 1, 28, 28)）
      filter_h : 필터의 높이
      filter_w : 필터의 너비
      stride : 스트라이드
      pad : 패딩
      
      Returns
      -------
      img : 변환된 이미지들
      """
      N, C, H, W = input_shape
      out_h = (H + 2*pad - filter_h)//stride + 1
      out_w = (W + 2*pad - filter_w)//stride + 1
      col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)
  
      img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))
      for y in range(filter_h):
          y_max = y + stride*out_h
          for x in range(filter_w):
              x_max = x + stride*out_w
              img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]
              # y~y_max사이에 stride 간격으로 뛰어서 출력
  
      return img[:, :, pad:H + pad, pad:W + pad]
```
  
  

### 7.4 풀링 계층 구현하기

> 풀링 적용 영역을 채널마다 독립적으로 전개!!!



<img src="밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-21-1614067869871.png" alt="fig 7-21" style="zoom:50%;" />

<img src="밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-22-1614067869872.png" alt="fig 7-22" style="zoom:50%;" />

- 파이썬 구현

  ```python
  class Pooling:
      def __init__(self, pool_h, pool_w, stride=1, pad=0):
          self.pool_h = pool_h
          self.pool_w = pool_w
          self.stride = stride
          self.pad = pad
          
          self.x = None
          self.arg_max = None
  
      def forward(self, x):
          N, C, H, W = x.shape
          out_h = int(1 + (H - self.pool_h) / self.stride)
          out_w = int(1 + (W - self.pool_w) / self.stride)
  		# 입력 데이터 전개
          col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)
          col = col.reshape(-1, self.pool_h*self.pool_w)
  
          # 행별 최대값 구함
          arg_max = np.argmax(col, axis=1)
          out = np.max(col, axis=1)
          
          # 적절한 모양으로 성형
          out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)
  
          self.x = x
          self.arg_max = arg_max
  
          return out
  
      def backward(self, dout):
          dout = dout.transpose(0, 2, 3, 1)
          
          pool_size = self.pool_h * self.pool_w
          dmax = np.zeros((dout.size, pool_size))
          dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()
          dmax = dmax.reshape(dout.shape + (pool_size,)) 
          
          dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)
          dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)
          
          return dx
  ```



---



## 5. CNN 구현하기

> Convolution - ReLU - Pooling - Affine - ReLU - Affine - Softmax

```python
class SimpleConvNet:
    """ Parameters
    ----------
    input_size : 입력 크기（MNIST의 경우엔 784）
    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）
    output_size : 출력 크기（MNIST의 경우엔 10）
    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'
    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）
        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정
        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정
    """
    # 초기화
    def __init__(self, input_dim=(1, 28, 28), # 입력 데이터의 차원(채널 수, 높이, 너비)
                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},
                 hidden_size=100, output_size=10, weight_init_std=0.01):
        # 하이퍼파라미터를 딕셔너리에서 꺼냄
        filter_num = conv_param['filter_num']
        filter_size = conv_param['filter_size']
        filter_pad = conv_param['pad']
        filter_stride = conv_param['stride']
        input_size = input_dim[1]
        # 합성곱 계층 출력 크기 계산
        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1
        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))

        # 가중치 초기화
        self.params = {}
        # 합성곱 계층
        self.params['W1'] = weight_init_std * \
                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)
        self.params['b1'] = np.zeros(filter_num)
        # 완전연결 계층1
        self.params['W2'] = weight_init_std * \
                            np.random.randn(pool_output_size, hidden_size)
        self.params['b2'] = np.zeros(hidden_size)
        # 완전연결 계층2
        self.params['W3'] = weight_init_std * \
                            np.random.randn(hidden_size, output_size)
        self.params['b3'] = np.zeros(output_size)

    
        # 계층 생성
        self.layers = OrderedDict()
        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],
                                           conv_param['stride'], conv_param['pad'])
        self.layers['Relu1'] = Relu()
        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)
        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])
        self.layers['Relu2'] = Relu()
        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])

        self.last_layer = SoftmaxWithLoss()

    # 추론
    def predict(self, x):
        for layer in self.layers.values():
            x = layer.forward(x)

        return x

    # 손실함수 값
    def loss(self, x, t):
        y = self.predict(x)
        return self.last_layer.forward(y, t)

    # 정확도 계산
    def accuracy(self, x, t, batch_size=100):
        if t.ndim != 1 : t = np.argmax(t, axis=1)
        
        acc = 0.0
        
        for i in range(int(x.shape[0] / batch_size)):
            tx = x[i*batch_size:(i+1)*batch_size]
            tt = t[i*batch_size:(i+1)*batch_size]
            y = self.predict(tx)
            y = np.argmax(y, axis=1)
            acc += np.sum(y == tt) 
        
        return acc / x.shape[0]

    def numerical_gradient(self, x, t):
        """기울기를 구한다（수치미분）
        ----------------------------------------------
        각 층의 기울기를 담은 사전(dictionary) 변수
            grads['W1']、grads['W2']、... 각 층의 가중치
            grads['b1']、grads['b2']、... 각 층의 편향
        """
        loss_w = lambda w: self.loss(x, t)

        grads = {}
        for idx in (1, 2, 3):
            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])
            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])

        return grads

    def gradient(self, x, t):
        #오차역전파법
        
        # forward
        self.loss(x, t)

        # backward
        dout = 1
        dout = self.last_layer.backward(dout)

        layers = list(self.layers.values())
        layers.reverse()
        for layer in layers:
            dout = layer.backward(dout)

        # 결과 저장
        grads = {}
        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db
        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db
        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db

        return grads
        
    def save_params(self, file_name="params.pkl"):
        params = {}
        for key, val in self.params.items():
            params[key] = val
        with open(file_name, 'wb') as f:
            pickle.dump(params, f)

    def load_params(self, file_name="params.pkl"):
        with open(file_name, 'rb') as f:
            params = pickle.load(f)
        for key, val in params.items():
            self.params[key] = val

        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):
            self.layers[key].W = self.params['W' + str(i+1)]
            self.layers[key].b = self.params['b' + str(i+1)]

```

<img src="밑시딥 7. 합성곱 신경망(CNN).assets/7-29.png" alt="7-29" style="zoom:50%;" /> 

`test acc:0.949`



---



## 6. CNN 시각화하기

> 합성곱 계층에서 입력으로 받은 이미지 데이터에서 무엇을 보고 있는지 알아보자.



### 6.1 가중치 시각화

```python
def filter_show(filters, nx=4, show_num=16):
    FN, C, FH, FW = filters.shape
    ny = int(np.ceil(show_num / nx))

    fig = plt.figure()
    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)
    # subplots_adjust : 다중 차트

    for i in range(show_num):
        ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])
        # add_subplot : 그래프를 그려넣을 그래프 격자 생성
        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')


network = SimpleConvNet(input_dim=(1,28,28), 
                        conv_param = {'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},
                        hidden_size=100, output_size=10, weight_init_std=0.01)

# 학습된 가중치
network.load_params("params.pkl")

# 첫번째 계층의 가중치 보여줌
filter_show(network.params['W1'], 16)

img = imread('../dataset/cactus_gray.png')
img = img.reshape(1, 1, *img.shape)

fig = plt.figure()

w_idx = 1

# 필터를 거친 출력이미지
for i in range(16):
    w = network.params['W1'][i]
    b = 0  # network.params['b1'][i]

    w = w.reshape(1, *w.shape)
    #b = b.reshape(1, *b.shape)
    conv_layer = Convolution(w, b) 
    out = conv_layer.forward(img)
    out = out.reshape(out.shape[2], out.shape[3])
    
    ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])
    # add_subplot : 그래프를 그려넣을 그래프 격자 생성
    ax.imshow(out, cmap=plt.cm.gray_r, interpolation='nearest')

plt.show()
```

<img src="밑시딥 7. 합성곱 신경망(CNN).assets/7-30.png" alt="7-30" style="zoom: 67%;" /> <img src="밑시딥 7. 합성곱 신경망(CNN).assets/7-31.png" alt="7-31" style="zoom:50%;" />

- 학습을 마친 필터는 규칙성 있는 이미지가 된다.

  - 규칙 : 색이 변화하는 필터와 덩어리(블롭, blob)가 진 필터 등

- **`에지(색상이 바뀐 경계선)와 블롭(국소적으로 덩어리진 영역)`**을 필터가 보고 있다.

  🔥 합성곱 계층의 필터는 에지나 블롭 등의 원시적인 정보를 추출함



### 6.2 깊이에 따른 추출 정보 변화

> 앞 절에서는 1번째 층의 합성곱 계층을 대상을 한 것으로 CNN의 각 계층은 어떤 정보가 추출되는지 알아보자.

<img src="밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-26.png" alt="fig 7-26" style="zoom:67%;" />

* dense : 완전연결계층

> 일반 사물 인식을 수행한 8층의 CNN(AlexNet)

##### 🔥 층이 깊어질수록 더 복잡하고 추상화된 정보가 추출 ==> 사물의 `의미`를 이해하도록 변화함



---



## 7. 대표적인 CNN

> CNN 네트워크인 LeNet과 AlexNet을 알아보자.



### 7.1 LeNet

> 손글씨 숫자를 인식하는 네트워크

![fig 7-27](밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-27.png)

- 현재의 CNN과의 차이점
  - 활성화 함수 : LeNet에서는 시그모이드 함수를 사용
  - 서브샘플링하여 중간 데이터의 크기를 줄임(현재는 최대 풀링이 주류)



### 7.1 AlexNet

<img src="밑시딥 7. 합성곱 신경망(CNN).assets/fig 7-28.png" alt="fig 7-28" style="zoom:50%;" /> 

- LeNet과의 차이점
  - 활성화 함수 :  ReLU함수를 사용
  - LRN(Local Response Normalization) : 국소적 정규화를 실시하는 계층을 이용
  - 드롭아웃 사용



