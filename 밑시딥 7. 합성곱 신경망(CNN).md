# ë°‘ì‹œë”¥ ğŸ“‚7. í•©ì„±ê³± ì‹ ê²½ë§(CNN)

> í•©ì„±ê³± ì‹ ê²½ë§(convolutional neural network)
>
> CNNì€ ì´ë¯¸ì§€ ì¸ì‹ê³¼ ìŒì„± ì¸ì‹ ë“±ì— ì‚¬ìš©ë˜ëŠ” ì‹ ê²½ë§ìœ¼ë¡œì¨ ì´ë¯¸ì§€ ì¸ì‹ ë¶„ì•¼ì˜ ê¸°ì´ˆê°€ ëœë‹¤.



## 1. ì „ì²´ êµ¬ì¡°

> CNNì—ì„œëŠ” ê¸°ì¡´ì˜ ì™„ì „ì—°ê²°(fully-connected)ì¸ Affine ê³„ì¸µë¿ë§Œ ì•„ë‹Œ **`í•©ì„±ê³± ê³„ì¸µ(Conv)`**ê³¼ **`í’€ë§ ê³„ì¸µ(Pooling)`**ì´ ì¶”ê°€ëœë‹¤.

![fig 7-2](ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-2.png)

- CNNì˜ ê³„ì¸µì€ 'Conv-ReLU-(Pooling)'íë¦„ìœ¼ë¡œ ì—°ê²°



## 2. í•©ì„±ê³± ê³„ì¸µ

> CNNì—ì„œëŠ” íŒ¨ë”©(padding), ìŠ¤íŠ¸ë¼ì´ë“œ(stride) ë“± ìƒˆë¡œìš´ ê°œë…ì´ ë“±ì¥í•˜ë©° ê³„ì¸µ ì‚¬ì´ì—ëŠ” ì…ì²´ì ì¸ ë°ì´í„°ê°€ íë¥¸ë‹¤.



### 2.1 ì™„ì „ì—°ê²° ê³„ì¸µì˜ ë¬¸ì œì 

> ì™„ì „ì—°ê²° ê³„ì¸µ : ì¸ì ‘í•˜ëŠ” ê³„ì¸µì˜ ë‰´ëŸ°ì´ ëª¨ë‘ ì—°ê²°

ğŸ”¥  ì™„ì „ì—°ê²° ê³„ì¸µì˜ ë‹¨ì  : <u>**`ë°ì´í„°ì˜ í˜•ìƒì´ ë¬´ì‹œ`**</u>

- ì´ë¯¸ì§€ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì„¸ë¡œ, ê°€ë¡œ, ì±„ë„(ìƒ‰ìƒ)ìœ¼ë¡œ êµ¬ì„±ëœ 3ì°¨ì› ë°ì´í„°ì´ë‹¤.

- ì™„ì „ì—°ê²° ê³„ì¸µì˜ ì…ë ¥ì€ <u>3ì°¨ì› ë°ì´í„°ë¥¼ í‰í‰í•œ 1ì°¨ì› ë°ì´í„°</u>ë¡œ í‰íƒ„í™”í•´ì¤˜ì•¼ í•¨

  ğŸ‘‰ 3ì°¨ì› ì†ì—ì„œ ì˜ë¯¸ë¥¼ ê°–ëŠ” ë³¸ì§ˆì ì¸ íŒ¨í„´ì´ ìˆ¨ì–´ ìˆì„ ê²ƒì¸ë° ì™„ì „ì—°ê²° ê³„ì¸µì€ í˜•ìƒì— ë‹´ê¸´ ì •ë³´ë¥¼ ì‚´ë¦´ ìˆ˜ ì—†ë‹¤.



âœ¨ íŠ¹ì§• ë§µ(feature map) : í•©ì„±ê³± ê³„ì¸µì˜ ì…ì¶œë ¥ ë°ì´í„°



### 2.2 í•©ì„±ê³± ì—°ì‚°

> í•©ì„±ê³± ì—°ì‚° : í•„í„° ì—°ì‚°

<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-3.png" alt="fig 7-3" style="zoom: 50%;" />  

> ì…ë ¥ê³¼ í•„í„°ì—ì„œ ëŒ€ì‘í•˜ëŠ” ì›ì†Œë¼ë¦¬ ê³±í•œ í›„ ê·¸ ì´í•©ì„ êµ¬í•¨ ===> `ë‹¨ì¼ ê³±ì…ˆ-ëˆ„ì‚°(FMA)`



<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-4.png" alt="fig 7-4" style="zoom:50%;" /> 

- ì™„ì „ì—°ê²° ì‹ ê²½ë§ì—ëŠ” ê°€ì¤‘ì¹˜ì™€ í¸í–¥ì´ ì¡´ì¬í•˜ì§€ë§Œ CNNì—ì„œëŠ” í•„í„°ê°€ ì¡´ì¬í•œë‹¤. ì¦‰, í•„í„°ê°€ ê°€ì¤‘ì¹˜ì˜ ì—­í• ì„ í•˜ëŠ” ê²ƒì´ë‹¤.

- í¸í–¥ ë˜í•œ ê³ ë ¤í•œë‹¤ë©´ ì•„ë˜ì™€ ê°™ìŒ. <u>í¸í–¥ì€ í•­ìƒ í•˜ë‚˜(1X1)ë§Œ ì¡´ì¬</u>

<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-5.png" alt="fig 7-5" style="zoom:50%;" /> 



### 2.3 íŒ¨ë”©(padding)

> ì…ë ¥ ë°ì´í„° ì£¼ë³€ì„ íŠ¹ì • ê°’ìœ¼ë¡œ ì±„ìš°ëŠ” ê²ƒ

- ì™œ ì‚¬ìš©?? ==> ì¶œë ¥ í¬ê¸°ë¥¼ ì¡°ì •í•  ëª©ì 
  - í•©ì„±ê³± ì—°ì‚°ì„ ê±°ì¹  ë•Œë§ˆë‹¤ í¬ê¸°ê°€ ì‘ì•„ì§€ë©´ ì–´ëŠ ì‹œì ì—ì„œëŠ” ì¶œë ¥ í¬ê¸°ê°€ 1ì´ ë˜ì–´ë²„ë¦¬ê¸° ë•Œë¬¸

<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-6.png" alt="fig 7-6" style="zoom:50%;" /> 



### 2.4 ìŠ¤íŠ¸ë¼ì´ë“œ(stride)

> í•„í„°ë¥¼ ì ìš©í•˜ëŠ” ìœ„ì¹˜ì˜ ê°„ê²©

- ìŠ¤íŠ¸ë¼ì´ë“œë¥¼ í‚¤ìš°ë©´ ì¶œë ¥ í¬ê¸°ëŠ” ì‘ì•„ì§„ë‹¤. ë°˜ëŒ€ë¡œ íŒ¨ë”©ì„ í‚¤ìš°ë©´ ì¶œë ¥ í¬ê¸°ëŠ” ì»¤ì§„ë‹¤. ì´ë¥¼ ìˆ˜ì‹í™”í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.

  <img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/e 7.1.png" alt="e 7.1" style="zoom:50%;" /> > 

  > ì…ë ¥ í¬ê¸° (H, W), í•„í„° í¬ê¸°(FH, FW), ì¶œë ¥ í¬ê¸°(OH, OW), íŒ¨ë”© P, ìŠ¤íŠ¸ë¼ì´ë“œ S
  >
  > ì¶œë ¥ í¬ê¸°ëŠ” ì •ìˆ˜ë¡œ ë–¨ì–´ì ¸ì•¼í•¨ì„ ì£¼ì˜!



### 2.5 3ì°¨ì› ë°ì´í„°ì˜ í•©ì„±ê³± ì—°ì‚°

> ì±„ë„ê¹Œì§€ ê³ ë ¤í•œ 3ì°¨ì› ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” í•©ì„±ê³± ì—°ì‚°ì„ ì‚´í´ë³´ì.

<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-9.png" alt="fig 7-9" style="zoom:50%;" /> 

> ì…ë ¥ ë°ì´í„°ì˜ ì±„ë„ ìˆ˜ì™€ í•„í„°ì˜ ì±„ë„ ìˆ˜ê°€ ê°™ì•„ì•¼ í•¨!



### 2.6 ë¸”ë¡ìœ¼ë¡œ ìƒê°í•˜ê¸°

> 3ì°¨ì› ë°ì´í„°ë¥¼ ë‹¤ì°¨ì› ë°°ì—´ë¡œ ë‚˜íƒ€ë‚¼ ë•ŒëŠ” (ì±„ë„, ë†’ì´, ë„ˆë¹„) ìˆœì„œë¥¼ ì“°ì.
>
> í•„í„° ë˜í•œ (ì±„ë„, í•„í„°ë†’ì´, í•„í„°ë„ˆë¹„)ë¡œ ë‚˜íƒ€ë‚¸ë‹¤ê³  í•˜ì.

<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-10.png" alt="fig 7-10" style="zoom:50%;" /> 

> ì¶œë ¥ì´ 2ì°¨ì›ìœ¼ë¡œ ë‚˜ì˜´(ì¶œë ¥ íŠ¹ì§• ë§µì´ í•œ ì¥) ==> 3ì°¨ì›ìœ¼ë¡œ ì¶œë ¥í• ë ¤ë©´? ğŸ‘‡



<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-11.png" alt="fig 7-11" style="zoom:50%;" /> 

> í•„í„°ë¥¼ ë‹¤ìˆ˜ ì‚¬ìš© ==> í•„í„° FNê°œ ì‚¬ìš©í•˜ë©´ ì¶œë ¥ ë˜í•œ FN ì¥ì˜ ì¶œë ¥ íŠ¹ì§• ë§µì´ ìƒê¹€
>
> ê°€ì¤‘ì¹˜ ë°ì´í„° = (ì¶œë ¥ ì±„ë„ ìˆ˜, ì…ë ¥ ì±„ë„ ìˆ˜, ë†’ì´, ë„ˆë¹„)



<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-12.png" alt="fig 7-12" style="zoom:50%;" /> 

> í¸í–¥ì€ ì±„ë„ í•˜ë‚˜ì— ê°’ í•˜ë‚˜ì”©ìœ¼ë¡œ êµ¬ì„±





### 2.7 ë°°ì¹˜ ì²˜ë¦¬

> ì…ë ¥ ë°ì´í„°ë¥¼ í•œ ë©ì–´ë¦¬ë¡œ ë¬¶ì–´ ë°°ì¹˜ ì²˜ë¦¬

<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-13.png" alt="fig 7-13" style="zoom: 50%;" /> 

> ë°ì´í„°ë¥¼ (ë°ì´í„° ìˆ˜, ì±„ë„ ìˆ˜, ë†’ì´, ë„ˆë¹„) ìˆœìœ¼ë¡œ ì €ì¥

- ì£¼ì˜í•  ì . ì‹ ê²½ë§ 4ì°¨ì› ë°ì´í„°ê°€ í•˜ë‚˜ íë¥¼ ë•Œë§ˆë‹¤ ë°ì´í„° Nê°œì— ëŒ€í•œ í•©ì„±ê³± ì—°ì‚°ì´ ì´ë¤„ì§ ==> NíšŒ ë¶„ì˜ ì²˜ë¦¬ë¥¼ í•œë²ˆì— ìˆ˜í–‰



---



## 3. í’€ë§ ê³„ì¸µ

> ì„¸ë¡œ, ê°€ë¡œ ë°©í–¥ì˜ ê³µê°„ì„ ì¤„ì´ëŠ” ì—°ì‚°

<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-14.png" alt="fig 7-14" style="zoom:50%;" />

- ìœ„ì˜ ê·¸ë¦¼ì€ **`ìµœëŒ€ í’€ë§(max pooling)`**ì„ ìŠ¤íŠ¸ë¼ì´ë“œ 2ë¡œ ì²˜ë¦¬í•œë‹¤. ë³´í†µ í’€ë§ì˜ ìœˆë„ìš° í¬ê¸°ì™€ ìŠ¤íŠ¸ë¼ì´ë“œëŠ” ê°™ì€ ê°’ìœ¼ë¡œ ì„¤ì •í•œë‹¤.
- í’€ë§ìœ¼ë¡œëŠ” í‰ê·  í’€ë§ ë“±ì´ ìˆì§€ë§Œ ì´ë¯¸ì§€ ì¸ì‹ ë¶„ì•¼ì—ì„œëŠ” ì£¼ë¡œ ìµœëŒ€ í’€ë§ì„ ì‚¬ìš©í•¨



### 3. 1 í’€ë§ ê³„ì¸µì˜ íŠ¹ì§•

1. í•™ìŠµí•´ì•¼ í•  ë§¤ê°œë³€ìˆ˜ ì—†ìŒ
2. ì±„ë„ ìˆ˜ê°€ ë³€í•˜ì§€ ì•ŠìŒ
   - ì±„ë„ë§ˆë‹¤ ë…ë¦½ì ìœ¼ë¡œ ê³„ì‚°í•˜ê¸° ë•Œë¬¸
3. ì…ë ¥ì˜ ë³€í™”ì— ì˜í–¥ì„ ì ê²Œ ë°›ìŒ(ê°•ê±´í•˜ë‹¤)
   - ë°ì´í„°ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ë„ ìˆìŒ



---



## 4. í•©ì„±ê³±/í’€ë§ ê³„ì¸µ êµ¬í˜„í•˜ê¸°

> í•©ì„±ê³±ê³¼ í’€ë§ ê³„ì¸µì„ íŒŒì´ì¬ìœ¼ë¡œ êµ¬í˜„í•´ë³´ì.



### 4.1 4ì°¨ì› ë°°ì—´

> CNNì—ì„œ ê³„ì¸µ ì‚¬ì´ë¡œ íë¥´ëŠ” ë°ì´í„°ëŠ” 4ì°¨ì›ì´ë‹¤.

```python
x = np.random.rand(10, 1, 28, 28)
x.shape # (10, 1, 28, 28)
# ë†’ì´ 28, ë„ˆë¹„ 28, ì±„ë„ 1ê°œì¸ ë°ì´í„°ê°€ 10ê°œ

x[i] # ê° ë°ì´í„° ì ‘ê·¼
x[i][j] # ì±„ë„ ì ‘ê·¼ (x[i, j])
```



### 4.2 im2colë¡œ ë°ì´í„° ì „ê°œí•˜ê¸°

> ë„˜íŒŒì´ ì—ì„œëŠ” ì›ì†Œì— ì ‘ê·¼í•  ë•Œ for ë¬¸ì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. ë–„ë¬¸ì— `im2col` ì´ë¼ëŠ” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨í•˜ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.

ğŸ™„ im2col : image to column

â€‹					 ğŸ‘‰ ì…ë ¥ ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ê¸° ì¢‹ê²Œ ì „ê°œí•˜ëŠ” í•¨ìˆ˜ë¡œ 4ì°¨ì› ë°ì´í„°ë¥¼ 2ì°¨ì›ìœ¼ë¡œ ë³€í™˜í•¨

<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-18.png" alt="fig 7-18" style="zoom:50%;" /> 

> ì…ë ¥ ë°ì´í„°ì—ì„œ í•„í„°ë¥¼ ì ìš©í•˜ëŠ” ì˜ì—­ì„ í•œ ì¤„ë¡œ ëŠ˜ì–´ë†“ëŠ”ë‹¤.

- ê·¸ë¦¼ì—ì„œëŠ”  í•„í„°ì˜ ì ìš© ì˜ì—­ì´ ê²¹ì¹˜ì§€ ì•Šì§€ë§Œ ì‹¤ì œ ìƒí™©ì—ì„œëŠ” ì˜ì—­ì´ ê²¹ì¹˜ëŠ” ê²½ìš°ê°€ ëŒ€ë¶€ë¶„

  ğŸ‘‰ im2colë¡œ ì „ê°œí•œ í›„ì˜ ì›ì†Œ ìˆ˜ê°€ ì›ë˜ ë¸”ë¡ì˜ ì›ì†Œ ìˆ˜ë³´ë‹¤ ë§ì•„ì§ ==> ë©”ëª¨ë¦¬ ë§ì´ ì†Œë¹„



<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-19.png" alt="fig 7-19" style="zoom:50%;" />

> í•©ì„±ê³± ê³„ì¸µì˜ í•„í„°ë¥¼ 1ì—´ë¡œ ì „ê°œí•˜ê³  ê³„ì‚°. 2ì°¨ì›ì¸ ì¶œë ¥ ë°ì´í„°ë¥¼ 4ì°¨ì›ìœ¼ë¡œ ë³€í˜•(reshape)í•´ì•¼í•¨



### 4.3 í•©ì„±ê³± ê³„ì¸µ êµ¬í˜„í•˜ê¸°

- im2col í•¨ìˆ˜

  ```python
  def im2col(input_data, filter_h, filter_w, stride=1, pad=0):
      """ë‹¤ìˆ˜ì˜ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ 2ì°¨ì› ë°°ì—´ë¡œ ë³€í™˜í•œë‹¤(í‰íƒ„í™”).
      
      Parameters
      ----------
      input_data : 4ì°¨ì› ë°°ì—´ í˜•íƒœì˜ ì…ë ¥ ë°ì´í„°(ì´ë¯¸ì§€ ìˆ˜, ì±„ë„ ìˆ˜, ë†’ì´, ë„ˆë¹„)
      filter_h : í•„í„°ì˜ ë†’ì´
      filter_w : í•„í„°ì˜ ë„ˆë¹„
      stride : ìŠ¤íŠ¸ë¼ì´ë“œ
      pad : íŒ¨ë”©
      
      Returns
      -------
      col : 2ì°¨ì› ë°°ì—´
      """
      N, C, H, W = input_data.shape
      out_h = (H + 2*pad - filter_h)//stride + 1
      out_w = (W + 2*pad - filter_w)//stride + 1
  
      img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')
      col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))
  
      for y in range(filter_h):
          y_max = y + stride*out_h
          for x in range(filter_w):
              x_max = x + stride*out_w
              col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]
  
      col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)
      # transpose() : ë‹¤ì°¨ì› ë°°ì—´ì˜ ì¶• ìˆœì„œë¥¼ ë°”ê¿”ì£¼ëŠ” í•¨ìˆ˜(ì¸ë±ìŠ¤ë¡œ ì¶•ì˜ ìˆœì„œë¥¼ ë³€ê²½) 
      # (N, C, filter_h, filter_w, out_h, out_w) => (N, out_h, out_w, C, filter_h, filter_w)
      # reshapeì— -1ì„ ì§€ì •í•˜ë©´ ë‹¤ì°¨ì› ë°°ì—´ì˜ ì› ìˆ˜ê°€ ë³€í™˜ í›„ì—ë„ ë˜‘ê°™ì´ ìœ ì§€ë˜ë„ë¡ ì ˆì íˆ ë¬¶ì–´ì¤Œ
      return col
  ```

- Convolution class

  ```python
  class Convolution:
      def __init__(self, W, b, stride=1, pad=0):
          self.W = W
          self.b = b
          self.stride = stride
          self.pad = pad
          
          # ì¤‘ê°„ ë°ì´í„°ï¼ˆbackward ì‹œ ì‚¬ìš©ï¼‰
          self.x = None   
          self.col = None
          self.col_W = None
          
          # ê°€ì¤‘ì¹˜ì™€ í¸í–¥ ë§¤ê°œë³€ìˆ˜ì˜ ê¸°ìš¸ê¸°
          self.dW = None
          self.db = None
  
      def forward(self, x):
          FN, C, FH, FW = self.W.shape
          N, C, H, W = x.shape
          out_h = 1 + int((H + 2*self.pad - FH) / self.stride)
          out_w = 1 + int((W + 2*self.pad - FW) / self.stride)
  
          col = im2col(x, FH, FW, self.stride, self.pad)
          col_W = self.W.reshape(FN, -1).T
  
          out = np.dot(col, col_W) + self.b
          out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)
  
          self.x = x
          self.col = col
          self.col_W = col_W
  
          return out
  
      def backward(self, dout):
          FN, C, FH, FW = self.W.shape
          dout = dout.transpose(0,2,3,1).reshape(-1, FN)
  
          self.db = np.sum(dout, axis=0)
          self.dW = np.dot(self.col.T, dout)
          self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)
  
          dcol = np.dot(dout, self.col_W.T)
          dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)
  
          return dx
  ```

- backward ì‹œ im2colì€ col2imí•¨ìˆ˜ë¡œ ì‚¬ìš©

  ```python
  def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):
      """(im2colê³¼ ë°˜ëŒ€) 2ì°¨ì› ë°°ì—´ì„ ì…ë ¥ë°›ì•„ ë‹¤ìˆ˜ì˜ ì´ë¯¸ì§€ ë¬¶ìŒìœ¼ë¡œ ë³€í™˜í•œë‹¤.
      
      Parameters
      ----------
      col : 2ì°¨ì› ë°°ì—´(ì…ë ¥ ë°ì´í„°)
      input_shape : ì›ë˜ ì´ë¯¸ì§€ ë°ì´í„°ì˜ í˜•ìƒï¼ˆì˜ˆï¼š(10, 1, 28, 28)ï¼‰
      filter_h : í•„í„°ì˜ ë†’ì´
      filter_w : í•„í„°ì˜ ë„ˆë¹„
      stride : ìŠ¤íŠ¸ë¼ì´ë“œ
      pad : íŒ¨ë”©
      
      Returns
      -------
      img : ë³€í™˜ëœ ì´ë¯¸ì§€ë“¤
      """
      N, C, H, W = input_shape
      out_h = (H + 2*pad - filter_h)//stride + 1
      out_w = (W + 2*pad - filter_w)//stride + 1
      col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)
  
      img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))
      for y in range(filter_h):
          y_max = y + stride*out_h
          for x in range(filter_w):
              x_max = x + stride*out_w
              img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]
              # y~y_maxì‚¬ì´ì— stride ê°„ê²©ìœ¼ë¡œ ë›°ì–´ì„œ ì¶œë ¥
  
      return img[:, :, pad:H + pad, pad:W + pad]
```
  
  

### 7.4 í’€ë§ ê³„ì¸µ êµ¬í˜„í•˜ê¸°

> í’€ë§ ì ìš© ì˜ì—­ì„ ì±„ë„ë§ˆë‹¤ ë…ë¦½ì ìœ¼ë¡œ ì „ê°œ!!!



<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-21-1614067869871.png" alt="fig 7-21" style="zoom:50%;" />

<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-22-1614067869872.png" alt="fig 7-22" style="zoom:50%;" />

- íŒŒì´ì¬ êµ¬í˜„

  ```python
  class Pooling:
      def __init__(self, pool_h, pool_w, stride=1, pad=0):
          self.pool_h = pool_h
          self.pool_w = pool_w
          self.stride = stride
          self.pad = pad
          
          self.x = None
          self.arg_max = None
  
      def forward(self, x):
          N, C, H, W = x.shape
          out_h = int(1 + (H - self.pool_h) / self.stride)
          out_w = int(1 + (W - self.pool_w) / self.stride)
  		# ì…ë ¥ ë°ì´í„° ì „ê°œ
          col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)
          col = col.reshape(-1, self.pool_h*self.pool_w)
  
          # í–‰ë³„ ìµœëŒ€ê°’ êµ¬í•¨
          arg_max = np.argmax(col, axis=1)
          out = np.max(col, axis=1)
          
          # ì ì ˆí•œ ëª¨ì–‘ìœ¼ë¡œ ì„±í˜•
          out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)
  
          self.x = x
          self.arg_max = arg_max
  
          return out
  
      def backward(self, dout):
          dout = dout.transpose(0, 2, 3, 1)
          
          pool_size = self.pool_h * self.pool_w
          dmax = np.zeros((dout.size, pool_size))
          dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()
          dmax = dmax.reshape(dout.shape + (pool_size,)) 
          
          dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)
          dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)
          
          return dx
  ```



---



## 5. CNN êµ¬í˜„í•˜ê¸°

> Convolution - ReLU - Pooling - Affine - ReLU - Affine - Softmax

```python
class SimpleConvNet:
    """ Parameters
    ----------
    input_size : ì…ë ¥ í¬ê¸°ï¼ˆMNISTì˜ ê²½ìš°ì—” 784ï¼‰
    hidden_size_list : ê° ì€ë‹‰ì¸µì˜ ë‰´ëŸ° ìˆ˜ë¥¼ ë‹´ì€ ë¦¬ìŠ¤íŠ¸ï¼ˆe.g. [100, 100, 100]ï¼‰
    output_size : ì¶œë ¥ í¬ê¸°ï¼ˆMNISTì˜ ê²½ìš°ì—” 10ï¼‰
    activation : í™œì„±í™” í•¨ìˆ˜ - 'relu' í˜¹ì€ 'sigmoid'
    weight_init_std : ê°€ì¤‘ì¹˜ì˜ í‘œì¤€í¸ì°¨ ì§€ì •ï¼ˆe.g. 0.01ï¼‰
        'relu'ë‚˜ 'he'ë¡œ ì§€ì •í•˜ë©´ 'He ì´ˆê¹ƒê°’'ìœ¼ë¡œ ì„¤ì •
        'sigmoid'ë‚˜ 'xavier'ë¡œ ì§€ì •í•˜ë©´ 'Xavier ì´ˆê¹ƒê°’'ìœ¼ë¡œ ì„¤ì •
    """
    # ì´ˆê¸°í™”
    def __init__(self, input_dim=(1, 28, 28), # ì…ë ¥ ë°ì´í„°ì˜ ì°¨ì›(ì±„ë„ ìˆ˜, ë†’ì´, ë„ˆë¹„)
                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},
                 hidden_size=100, output_size=10, weight_init_std=0.01):
        # í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ì—ì„œ êº¼ëƒ„
        filter_num = conv_param['filter_num']
        filter_size = conv_param['filter_size']
        filter_pad = conv_param['pad']
        filter_stride = conv_param['stride']
        input_size = input_dim[1]
        # í•©ì„±ê³± ê³„ì¸µ ì¶œë ¥ í¬ê¸° ê³„ì‚°
        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1
        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))

        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
        self.params = {}
        # í•©ì„±ê³± ê³„ì¸µ
        self.params['W1'] = weight_init_std * \
                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)
        self.params['b1'] = np.zeros(filter_num)
        # ì™„ì „ì—°ê²° ê³„ì¸µ1
        self.params['W2'] = weight_init_std * \
                            np.random.randn(pool_output_size, hidden_size)
        self.params['b2'] = np.zeros(hidden_size)
        # ì™„ì „ì—°ê²° ê³„ì¸µ2
        self.params['W3'] = weight_init_std * \
                            np.random.randn(hidden_size, output_size)
        self.params['b3'] = np.zeros(output_size)

    
        # ê³„ì¸µ ìƒì„±
        self.layers = OrderedDict()
        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],
                                           conv_param['stride'], conv_param['pad'])
        self.layers['Relu1'] = Relu()
        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)
        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])
        self.layers['Relu2'] = Relu()
        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])

        self.last_layer = SoftmaxWithLoss()

    # ì¶”ë¡ 
    def predict(self, x):
        for layer in self.layers.values():
            x = layer.forward(x)

        return x

    # ì†ì‹¤í•¨ìˆ˜ ê°’
    def loss(self, x, t):
        y = self.predict(x)
        return self.last_layer.forward(y, t)

    # ì •í™•ë„ ê³„ì‚°
    def accuracy(self, x, t, batch_size=100):
        if t.ndim != 1 : t = np.argmax(t, axis=1)
        
        acc = 0.0
        
        for i in range(int(x.shape[0] / batch_size)):
            tx = x[i*batch_size:(i+1)*batch_size]
            tt = t[i*batch_size:(i+1)*batch_size]
            y = self.predict(tx)
            y = np.argmax(y, axis=1)
            acc += np.sum(y == tt) 
        
        return acc / x.shape[0]

    def numerical_gradient(self, x, t):
        """ê¸°ìš¸ê¸°ë¥¼ êµ¬í•œë‹¤ï¼ˆìˆ˜ì¹˜ë¯¸ë¶„ï¼‰
        ----------------------------------------------
        ê° ì¸µì˜ ê¸°ìš¸ê¸°ë¥¼ ë‹´ì€ ì‚¬ì „(dictionary) ë³€ìˆ˜
            grads['W1']ã€grads['W2']ã€... ê° ì¸µì˜ ê°€ì¤‘ì¹˜
            grads['b1']ã€grads['b2']ã€... ê° ì¸µì˜ í¸í–¥
        """
        loss_w = lambda w: self.loss(x, t)

        grads = {}
        for idx in (1, 2, 3):
            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])
            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])

        return grads

    def gradient(self, x, t):
        #ì˜¤ì°¨ì—­ì „íŒŒë²•
        
        # forward
        self.loss(x, t)

        # backward
        dout = 1
        dout = self.last_layer.backward(dout)

        layers = list(self.layers.values())
        layers.reverse()
        for layer in layers:
            dout = layer.backward(dout)

        # ê²°ê³¼ ì €ì¥
        grads = {}
        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db
        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db
        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db

        return grads
        
    def save_params(self, file_name="params.pkl"):
        params = {}
        for key, val in self.params.items():
            params[key] = val
        with open(file_name, 'wb') as f:
            pickle.dump(params, f)

    def load_params(self, file_name="params.pkl"):
        with open(file_name, 'rb') as f:
            params = pickle.load(f)
        for key, val in params.items():
            self.params[key] = val

        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):
            self.layers[key].W = self.params['W' + str(i+1)]
            self.layers[key].b = self.params['b' + str(i+1)]

```

<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/7-29.png" alt="7-29" style="zoom:50%;" /> 

`test acc:0.949`



---



## 6. CNN ì‹œê°í™”í•˜ê¸°

> í•©ì„±ê³± ê³„ì¸µì—ì„œ ì…ë ¥ìœ¼ë¡œ ë°›ì€ ì´ë¯¸ì§€ ë°ì´í„°ì—ì„œ ë¬´ì—‡ì„ ë³´ê³  ìˆëŠ”ì§€ ì•Œì•„ë³´ì.



### 6.1 ê°€ì¤‘ì¹˜ ì‹œê°í™”

```python
def filter_show(filters, nx=4, show_num=16):
    FN, C, FH, FW = filters.shape
    ny = int(np.ceil(show_num / nx))

    fig = plt.figure()
    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)
    # subplots_adjust : ë‹¤ì¤‘ ì°¨íŠ¸

    for i in range(show_num):
        ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])
        # add_subplot : ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ë„£ì„ ê·¸ë˜í”„ ê²©ì ìƒì„±
        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')


network = SimpleConvNet(input_dim=(1,28,28), 
                        conv_param = {'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},
                        hidden_size=100, output_size=10, weight_init_std=0.01)

# í•™ìŠµëœ ê°€ì¤‘ì¹˜
network.load_params("params.pkl")

# ì²«ë²ˆì§¸ ê³„ì¸µì˜ ê°€ì¤‘ì¹˜ ë³´ì—¬ì¤Œ
filter_show(network.params['W1'], 16)

img = imread('../dataset/cactus_gray.png')
img = img.reshape(1, 1, *img.shape)

fig = plt.figure()

w_idx = 1

# í•„í„°ë¥¼ ê±°ì¹œ ì¶œë ¥ì´ë¯¸ì§€
for i in range(16):
    w = network.params['W1'][i]
    b = 0  # network.params['b1'][i]

    w = w.reshape(1, *w.shape)
    #b = b.reshape(1, *b.shape)
    conv_layer = Convolution(w, b) 
    out = conv_layer.forward(img)
    out = out.reshape(out.shape[2], out.shape[3])
    
    ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])
    # add_subplot : ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ë„£ì„ ê·¸ë˜í”„ ê²©ì ìƒì„±
    ax.imshow(out, cmap=plt.cm.gray_r, interpolation='nearest')

plt.show()
```

<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/7-30.png" alt="7-30" style="zoom: 67%;" /> <img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/7-31.png" alt="7-31" style="zoom:50%;" />

- í•™ìŠµì„ ë§ˆì¹œ í•„í„°ëŠ” ê·œì¹™ì„± ìˆëŠ” ì´ë¯¸ì§€ê°€ ëœë‹¤.

  - ê·œì¹™ : ìƒ‰ì´ ë³€í™”í•˜ëŠ” í•„í„°ì™€ ë©ì–´ë¦¬(ë¸”ë¡­, blob)ê°€ ì§„ í•„í„° ë“±

- **`ì—ì§€(ìƒ‰ìƒì´ ë°”ë€ ê²½ê³„ì„ )ì™€ ë¸”ë¡­(êµ­ì†Œì ìœ¼ë¡œ ë©ì–´ë¦¬ì§„ ì˜ì—­)`**ì„ í•„í„°ê°€ ë³´ê³  ìˆë‹¤.

  ğŸ”¥ í•©ì„±ê³± ê³„ì¸µì˜ í•„í„°ëŠ” ì—ì§€ë‚˜ ë¸”ë¡­ ë“±ì˜ ì›ì‹œì ì¸ ì •ë³´ë¥¼ ì¶”ì¶œí•¨



### 6.2 ê¹Šì´ì— ë”°ë¥¸ ì¶”ì¶œ ì •ë³´ ë³€í™”

> ì• ì ˆì—ì„œëŠ” 1ë²ˆì§¸ ì¸µì˜ í•©ì„±ê³± ê³„ì¸µì„ ëŒ€ìƒì„ í•œ ê²ƒìœ¼ë¡œ CNNì˜ ê° ê³„ì¸µì€ ì–´ë–¤ ì •ë³´ê°€ ì¶”ì¶œë˜ëŠ”ì§€ ì•Œì•„ë³´ì.

<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-26.png" alt="fig 7-26" style="zoom:67%;" />

* dense : ì™„ì „ì—°ê²°ê³„ì¸µ

> ì¼ë°˜ ì‚¬ë¬¼ ì¸ì‹ì„ ìˆ˜í–‰í•œ 8ì¸µì˜ CNN(AlexNet)

##### ğŸ”¥ ì¸µì´ ê¹Šì–´ì§ˆìˆ˜ë¡ ë” ë³µì¡í•˜ê³  ì¶”ìƒí™”ëœ ì •ë³´ê°€ ì¶”ì¶œ ==> ì‚¬ë¬¼ì˜ `ì˜ë¯¸`ë¥¼ ì´í•´í•˜ë„ë¡ ë³€í™”í•¨



---



## 7. ëŒ€í‘œì ì¸ CNN

> CNN ë„¤íŠ¸ì›Œí¬ì¸ LeNetê³¼ AlexNetì„ ì•Œì•„ë³´ì.



### 7.1 LeNet

> ì†ê¸€ì”¨ ìˆ«ìë¥¼ ì¸ì‹í•˜ëŠ” ë„¤íŠ¸ì›Œí¬

![fig 7-27](ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-27.png)

- í˜„ì¬ì˜ CNNê³¼ì˜ ì°¨ì´ì 
  - í™œì„±í™” í•¨ìˆ˜ : LeNetì—ì„œëŠ” ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©
  - ì„œë¸Œìƒ˜í”Œë§í•˜ì—¬ ì¤‘ê°„ ë°ì´í„°ì˜ í¬ê¸°ë¥¼ ì¤„ì„(í˜„ì¬ëŠ” ìµœëŒ€ í’€ë§ì´ ì£¼ë¥˜)



### 7.1 AlexNet

<img src="ë°‘ì‹œë”¥ 7. í•©ì„±ê³± ì‹ ê²½ë§(CNN).assets/fig 7-28.png" alt="fig 7-28" style="zoom:50%;" /> 

- LeNetê³¼ì˜ ì°¨ì´ì 
  - í™œì„±í™” í•¨ìˆ˜ :  ReLUí•¨ìˆ˜ë¥¼ ì‚¬ìš©
  - LRN(Local Response Normalization) : êµ­ì†Œì  ì •ê·œí™”ë¥¼ ì‹¤ì‹œí•˜ëŠ” ê³„ì¸µì„ ì´ìš©
  - ë“œë¡­ì•„ì›ƒ ì‚¬ìš©



